apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Values.spanNormalizerConfig.name }}
  labels:
    release: {{ .Release.Name }}
data:
  application.conf: |-
    kafka.streams.config {
      application.id = jaeger-spans-to-raw-spans-job
      bootstrap.servers = "{{ .Values.spanNormalizerConfig.kafkaStreamsConfig.bootstrapServers }}"
      schema.registry.url = "{{ .Values.spanNormalizerConfig.kafkaStreamsConfig.schemaRegistryUrl }}"
      # kafka streams config
      num.stream.threads = "{{ int .Values.spanNormalizerConfig.kafkaStreamsConfig.numStreamThreads }}"
      commit.interval.ms = "{{ int .Values.spanNormalizerConfig.kafkaStreamsConfig.commitIntervalMs }}"
      # Common client (prodcuer, consumer, admin) configs
      receive.buffer.bytes = "{{ int .Values.spanNormalizerConfig.kafkaStreamsConfig.receiveBufferBytes }}"
      send.buffer.bytes = "{{ int .Values.spanNormalizerConfig.kafkaStreamsConfig.sendBufferBytes }}"
      # Producer configs
      producer.acks = "{{ .Values.spanNormalizerConfig.kafkaStreamsConfig.producerAcks }}"
      producer.batch.size = "{{ int .Values.spanNormalizerConfig.kafkaStreamsConfig.producerBatchSize }}"
      producer.linger.ms = "{{ int .Values.spanNormalizerConfig.kafkaStreamsConfig.producerLingerMs }}"
      producer.compression.type = "{{ .Values.spanNormalizerConfig.kafkaStreamsConfig.producerCompressionType }}"
      producer.max.request.size = "{{ int .Values.spanNormalizerConfig.kafkaStreamsConfig.producerMaxRequestSize }}"
      producer.buffer.memory = "{{ int .Values.spanNormalizerConfig.kafkaStreamsConfig.producerBufferMemory }}"
      # Consumer configs
      consumer.max.partition.fetch.bytes = "{{ int .Values.spanNormalizerConfig.kafkaStreamsConfig.consumerMaxPartitionFetchBytes }}"
      consumer.max.poll.records = "{{ int .Values.spanNormalizerConfig.kafkaStreamsConfig.consumerMaxPollRecords }}"
      consumer.session.timeout.ms = "{{ int .Values.spanNormalizerConfig.kafkaStreamsConfig.consumerSessionTimeoutMs }}"
      # Others
      metrics.recording.level = "{{ .Values.spanNormalizerConfig.kafkaStreamsConfig.metricsRecordingLevel }}"
      {{- if .Values.spanNormalizerConfig.extraKafkaStreamsConfig }}
      {{- range $key,$value := .Values.spanNormalizerConfig.extraKafkaStreamsConfig }}
      {{ $key }} = {{ $value }}
      {{- end }}
      {{- end }}
    }

    {{- if hasKey .Values.spanNormalizerConfig "processor" }}
    processor {
      {{- if hasKey .Values.spanNormalizerConfig.processor "tenantIdTagKey" }}
      tenantIdTagKey = "{{ .Values.spanNormalizerConfig.processor.tenantIdTagKey }}"
      {{- end }}

      {{- if hasKey .Values.spanNormalizerConfig.processor "excludeTenantIds" }}
      excludeTenantIds = {{ .Values.spanNormalizerConfig.processor.excludeTenantIds | toJson }}
      {{- end }}

      {{- if hasKey .Values.spanNormalizerConfig.processor "defaultTenantId" }}
      defaultTenantId = "{{ .Values.spanNormalizerConfig.processor.defaultTenantId }}"
      {{- end }}
    }
    {{- end }}

    {{- if hasKey .Values.spanNormalizerConfig "metrics" }}
    metrics {
      reporter {
        names = {{- toJson .Values.spanNormalizerConfig.metrics.reporter.names | trim | nindent 12 }}
      }
    }
    {{- end }}
