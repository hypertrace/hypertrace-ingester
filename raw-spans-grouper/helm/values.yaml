#
# Note about Namespace
# --------------------
# It is deliberately left out here and using the helm -n or --namespace flag you can deploy your resources to the same
# namespace as the release. If you leave it out, your resources will be deployed to the default namespace.
# Also, not that the namespace you are deploying to should already exist otherwise the helm command will fail.
# You can always specify a different namespace for a resource by setting it directly in it's yaml file or
# making it configurable by defining it in this file.

###########
# Deployment
###########
name: raw-spans-grouper
replicaCount: 2
maxUnavailable: 0

image:
  repository: hypertrace/raw-spans-grouper
  pullPolicy: IfNotPresent
  tagOverride: ""

imagePullSecrets: []

nodeLabels: {}

tolerations: []

securityContext: {}

# This is defined in resources/configs/common/application.conf as service.admin.port
containerAdminPort: 8099

javaOpts: "-XX:InitialRAMPercentage=50.0 -XX:MaxRAMPercentage=50.0 -XX:MaxDirectMemorySize=128M"

livenessProbe:
  initialDelaySeconds: 10
  periodSeconds: 5

readinessProbe:
  initialDelaySeconds: 2
  periodSeconds: 5

resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  requests:
    cpu: 0.2
    memory: 2Gi
  limits:
    cpu: 1.0
    memory: 2Gi

deploymentLabels:
  app: raw-spans-grouper

podLabels:
  app: raw-spans-grouper

podAnnotations: {}

# The Deployment Selector match labels are different from the pod labels. Note that they should be a subset of the pod
# labels. You append new labels to them but cannot remove labels. If you remove or modify the labels you will need to
# delete the existing deployment bearing the same name and then redeploy. This is the reason why they are separated from
# the pod labels. You can add and remove pod labels without having an effect on the deployment.
# Also, please use "apiVersion: apps/v1" instead of the deprecated "apiVersion: extensions/v1beta1" for the deployment
# apiVersion in the yaml file.
deploymentSelectorMatchLabels:
  app: raw-spans-grouper

statefulSetSelectorMatchLabels:
  app: raw-spans-grouper

serviceSelectorMatchLabels:
  app: raw-spans-grouper

volumeClaimTemplates:
  name: raw-spans-grouper-rocksdb
  storageClassName: kafka-streams-rocksdb
  storageRequestSize: 50Gi

###########
# Config Maps
###########
rawSpansGrouperConfig:
  name: raw-spans-grouper-config
  kafkaStreamsConfig:
    bootstrapServers: "bootstrap:9092"
    schemaRegistryUrl: "http://schema-registry-service:8081"
    #  Core configs
    numStreamThreads: 4 # default = 1
    commitIntervalMs: 30000 # default = 30000
    cacheMaxBytesBuffering: 134217728 # default = 10485760 (10MB)
    # Common client (prodcuer, consumer, admin) configs
    receiveBufferBytes: 4194304 # default = 32768 (kafka streams default)
    sendBufferBytes: 4194304 # default = 131072 (kafka streams default)
    # Producer configs
    producerAcks: all # default: 1
    producerBatchSize: 524288 # default = 16384
    producerLingerMs: 1000 # default = 100 (kafka streams default)
    producerCompressionType: "gzip" # default = none
    producerMaxRequestSize: 2097152 # default = 1048576
    producerBufferMemory: 134217728 # default = 33554432
    # Consumer configs
    consumerMaxPartitionFetchBytes: 8388608 # default = 1048576
    consumerMaxPollRecords: 1000 # default = 1000 (kafka streams default)
    consumerSessionTimeoutMs: 300000 # default = 10000
    # Changelog topic configs
    replicationFactor: 3
    # RocksDB state store configs
    rocksdbCacheTotalCapacity: 134217728
    rocksdbCacheWriteBuffersRatio: 0.3
    rocksdbCacheHighPriorityPoolRatio: 0.1
    rocksdbWriteBufferSize: 8388608
    rocksdbMaxWriteBuffers: 2
    rocksdbCacheIndexAndFilterBlocks: true
    # Exception handler configs
    defaultProductionExceptionHandler: "org.hypertrace.core.kafkastreams.framework.exceptionhandlers.IgnoreProductionExceptionHandler"
    ignoreProductionExceptionClasses: "org.apache.kafka.common.errors.RecordTooLargeException"
    # Others
    metricsRecordingLevel: INFO # default = INFO
  # All other streams config goes here.
  # Remove the flower braces and add key: value pair here.
  extraKafkaStreamsConfig: {}

  span:
    groupby:
      internal: 30

  defaultMaxSpanCount: 1000

logConfig:
  name: raw-spans-grouper-log-config
  monitorInterval: 30
  rootLogger:
    level: INFO
  appender:
    rolling:
      enabled: false

kafka-topic-creator:
  enabled: true
  jobName: structured-traces-from-raw-spans-kafka-topic-creator
  helmHook: pre-install,pre-upgrade
  kafka:
    topics:
      structured-traces-from-raw-spans:
        replicationFactor: 3
        partitions: 8
        configs:
          retention.bytes: 8589934592 # default = -1
          retention.ms: 86400000 # default = 604800000 (7 days)
          max.message.bytes: 10485760 # default = 1048588

  zookeeper:
    address: zookeeper:2181
  imagePullSecrets: []
  podAnnotations: {}
